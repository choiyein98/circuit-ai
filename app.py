import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
from PIL import Image
from collections import defaultdict
import os

# ==========================================
# [1. ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ]
# ==========================================
st.set_page_config(page_title="BrainBoard V58: Final Stable", layout="wide")

REAL_MODEL_PATHS = ['best.pt', 'best(2).pt', 'best(3).pt']
MODEL_SYM_PATH = 'symbol.pt'

@st.cache_resource
def load_all_models():
    reals = []
    for p in REAL_MODEL_PATHS:
        if os.path.exists(p): reals.append(YOLO(p))
    # symbol.pt íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ë¥¼ ë°˜ë“œì‹œ ì²´í¬í•©ë‹ˆë‹¤.
    sym = YOLO(MODEL_SYM_PATH) if os.path.exists(MODEL_SYM_PATH) else None
    return reals, sym

models_real, model_sym = load_all_models()

# ==========================================
# [2. Helper Functions]
# ==========================================
def normalize_name(raw_name):
    name = raw_name.lower().strip()
    if any(x in name for x in ['res', 'r']): return 'RESISTOR'
    if any(x in name for x in ['cap', 'c']): return 'CAPACITOR'
    if any(x in name for x in ['v', 'volt', 'batt', 'source', 'vdc']): return 'SOURCE'
    return 'OTHER'

def get_relation_key(p1, p2):
    return "-".join(sorted([p1, p2]))

# ==========================================
# [3. ì•Œê³ ë¦¬ì¦˜ 1: íšŒë¡œë„(ì •ë‹µì§€) ì¶”ì¶œ]
# ==========================================
def analyze_schematic_gold(img, model):
    if model is None: return img, set() # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ë¹ˆ ì„¸íŠ¸ ë°˜í™˜
    
    res = model.predict(source=img, conf=0.15, imgsz=640, verbose=False)
    parts = []
    for b in res[0].boxes:
        name = normalize_name(model.names[int(b.cls[0])])
        if name != 'OTHER':
            coords = b.xyxy[0].tolist()
            parts.append({'name': name, 'box': coords, 'center': ((coords[0]+coords[2])/2, (coords[1]+coords[3])/2)})
    
    gold_netlist = set()
    for i in range(len(parts)):
        for j in range(i + 1, len(parts)):
            p1, p2 = parts[i], parts[j]
            dist = math.sqrt((p1['center'][0]-p2['center'][0])**2 + (p1['center'][1]-p2['center'][1])**2)
            if dist < 300: # íšŒë¡œë„ ë‚´ ì—°ê²° ê±°ë¦¬ ê¸°ì¤€
                gold_netlist.add(get_relation_key(p1['name'], p2['name']))
    
    # ì‹œê°í™” (ì •ë‹µ í™•ì¸ìš©)
    for p in parts:
        x1, y1, x2, y2 = map(int, p['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img, p['name'], (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
    return img, gold_netlist

# ==========================================
# [4. ì•Œê³ ë¦¬ì¦˜ 2: ì‹¤ë¬¼ ë¶„ì„ ë° ëŒ€ì¡°]
# ==========================================
def analyze_real_verify(img, model_list, gold_netlist):
    h, w, _ = img.shape
    raw_bodies, raw_legs = [], []
    bb_box = [w*0.1, h*0.2, w*0.9, h*0.8]

    for m in model_list:
        res = m.predict(source=img, conf=0.1, imgsz=640, verbose=False)
        for b in res[0].boxes:
            name_idx = int(b.cls[0])
            name = m.names[name_idx].lower()
            coords = b.xyxy[0].tolist()
            center = ((coords[0]+coords[2])/2, (coords[1]+coords[3])/2)
            
            if 'breadboard' in name: bb_box = coords
            elif any(x in name for x in ['pin', 'leg', 'lead']):
                raw_legs.append({'center': center})
            elif 'wire' not in name:
                raw_bodies.append({'name': normalize_name(name), 'box': coords, 'center': center})

    # ë§ˆë””(Node) ì¶”ì 
    part_to_nodes = defaultdict(set)
    for i, p in enumerate(raw_bodies):
        node_id = int(((p['center'][0] - bb_box[0]) / max(1, bb_box[2] - bb_box[0])) * 60)
        part_to_nodes[i].add(node_id)

    # ì‹¤ë¬¼ ë„·ë¦¬ìŠ¤íŠ¸ ìƒì„±
    current_netlist = set()
    errors = []
    for i in range(len(raw_bodies)):
        for j in range(i + 1, len(raw_bodies)):
            if part_to_nodes[i].intersection(part_to_nodes[j]):
                current_netlist.add(get_relation_key(raw_bodies[i]['name'], raw_bodies[j]['name']))

    # ì •ë‹µì§€ ëŒ€ì¡°
    for ref in gold_netlist:
        if ref not in current_netlist:
            errors.append(f"âŒ ë°°ì„  ëˆ„ë½: íšŒë¡œë„ì—ëŠ” ìˆëŠ” {ref} ì—°ê²°ì´ ì‹¤ë¬¼ì—ëŠ” ì—†ìŠµë‹ˆë‹¤.")
    
    # [ì‚¬ìš©ì ì§€ì  ì‚¬í•­] íë¦„ ì—­ì „ ë°©ì§€
    for node, p_indices in part_to_nodes.items():
        roles = [raw_bodies[idx]['name'] for idx in p_indices]
        if 'SOURCE' in roles and 'CAPACITOR' in roles:
            errors.append(f"âš ï¸ ì˜¤ê²°ì„ : ì»¤íŒ¨ì‹œí„°ê°€ ì €í•­ì„ ê±°ì¹˜ì§€ ì•Šê³  ì „ì›ì— ì§ì ‘ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ì‹¤ë¬¼ ì‹œê°í™”
    for p in raw_bodies:
        x1, y1, x2, y2 = map(int, p['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)
        cv2.putText(img, p['name'], (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return img, errors

# ==========================================
# [5. ë©”ì¸ UI]
# ==========================================
st.title("ğŸ§  BrainBoard V58: Full Circuit Matcher")

if model_sym is None:
    st.error("âš ï¸ symbol.pt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ íšŒë¡œë„ ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."); st.stop()

col1, col2 = st.columns(2)
ref_file = col1.file_uploader("1. íšŒë¡œë„(ì •ë‹µì§€)", type=['jpg', 'png', 'jpeg'])
tgt_file = col2.file_uploader("2. ì‹¤ë¬¼ ì‚¬ì§„(ê²€ì¦ ëŒ€ìƒ)", type=['jpg', 'png', 'jpeg'])

if ref_file and tgt_file:
    if st.button("ğŸš€ ì •ë°€ ëŒ€ì¡° ë¶„ì„ ì‹œì‘"):
        try:
            ref_cv = cv2.cvtColor(np.array(Image.open(ref_file)), cv2.COLOR_RGB2BGR)
            tgt_cv = cv2.cvtColor(np.array(Image.open(tgt_file)), cv2.COLOR_RGB2BGR)

            # 1. íšŒë¡œë„ ì •ë‹µì§€ ì¶”ì¶œ
            res_ref_img, gold_netlist = analyze_schematic_gold(ref_cv, model_sym)
            # 2. ì‹¤ë¬¼ ê²€ì¦
            res_tgt_img, errors = analyze_real_verify(tgt_cv, models_real, gold_netlist)

            st.divider()
            if not errors: st.success("ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! íšŒë¡œë„ì™€ ì‹¤ë¬¼ ë°°ì„ ì´ ì™„ë²½íˆ ì¼ì¹˜í•©ë‹ˆë‹¤.")
            else:
                for e in errors: st.error(e)

            st.image(cv2.cvtColor(res_ref_img, cv2.COLOR_BGR2RGB), caption="íšŒë¡œë„ ë¶„ì„ (ì •ë‹µ ë§ˆë”” ì¶”ì¶œ)")
            st.image(cv2.cvtColor(res_tgt_img, cv2.COLOR_BGR2RGB), caption="ì‹¤ë¬¼ ë¶„ì„ (ë°°ì„  ì˜¤ë¥˜ ê²€ì¦)")
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
