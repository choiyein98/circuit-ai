import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
from PIL import Image
from collections import defaultdict
import gc

# ==========================================
# [ì„¤ì •] BrainBoard V67: Robust Hybrid
# ==========================================
st.set_page_config(page_title="BrainBoard V67: Hybrid", layout="wide")

REAL_MODEL_PATH = 'best(3).pt' 
MODEL_SYM_PATH = 'symbol.pt'

# ==========================================
# [Helper Functions]
# ==========================================
def resize_image_smart(image, max_size=1024):
    h, w = image.shape[:2]
    if max(h, w) > max_size:
        scale = max_size / max(h, w)
        new_w, new_h = int(w * scale), int(h * scale)
        return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return image

def get_center(box):
    return ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)

def calculate_iou(box1, box2):
    x1 = max(box1[0], box2[0]); y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2]); y2 = min(box1[3], box2[3])
    inter = max(0, x2 - x1) * max(0, y2 - y1)
    union = ((box1[2]-box1[0])*(box1[3]-box1[1])) + ((box2[2]-box2[0])*(box2[3]-box2[1])) - inter
    return inter / union if union > 0 else 0

def normalize_name(name):
    name = name.lower()
    if 'res' in name: return 'resistor'
    if 'cap' in name: return 'capacitor'
    if 'wire' in name: return 'wire'
    if any(x in name for x in ['source', 'batt', 'volt', 'vdc']): return 'source'
    if any(x in name for x in ['leg', 'pin', 'lead']): return 'leg'
    return name

def solve_overlap_real(parts):
    if not parts: return []
    # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    parts.sort(key=lambda x: x.get('conf', 0), reverse=True)
    final = []
    for curr in parts:
        is_dup = False
        for k in final:
            iou = calculate_iou(curr['box'], k['box'])
            dist = math.sqrt((curr['center'][0]-k['center'][0])**2 + (curr['center'][1]-k['center'][1])**2)
            # ê²¹ì¹˜ê±°ë‚˜ ë„ˆë¬´ ê°€ê¹Œìš°ë©´ ì¤‘ë³µ ì œê±° (ê±°ë¦¬ ê¸°ì¤€ 60px)
            if curr['name'] != 'leg' and (iou > 0.4 or dist < 60): 
                is_dup = True; break
        if not is_dup: final.append(curr)
    return final

# ==========================================
# [Logic] ìœ„ì¹˜ ê¸°ë°˜ ìˆœì„œ ì¶”ì¶œ (Spatial Sort)
# ==========================================
def extract_spatial_sequence(parts, image_width):
    # 1. Xì¢Œí‘œ ê¸°ì¤€ ì •ë ¬
    sorted_parts = sorted(parts, key=lambda x: x['center'][0])
    
    sequence = []
    current_stage = []
    
    if not sorted_parts: return []

    current_stage.append(sorted_parts[0])
    last_x = sorted_parts[0]['center'][0]
    
    # 2. ê·¸ë£¹í™” (ì´ë¯¸ì§€ ë„ˆë¹„ì˜ 15% ì´ë‚´ë©´ ê°™ì€ ë‹¨ê³„ë¡œ ê°„ì£¼)
    threshold = image_width * 0.15 
    
    for i in range(1, len(sorted_parts)):
        curr = sorted_parts[i]
        curr_x = curr['center'][0]
        
        if abs(curr_x - last_x) < threshold:
            current_stage.append(curr)
        else:
            # Yì¢Œí‘œ ì •ë ¬ (ìœ„->ì•„ë˜)
            current_stage.sort(key=lambda x: x['center'][1])
            sequence.append(current_stage)
            current_stage = [curr]
            last_x = curr_x
            
    if current_stage:
        current_stage.sort(key=lambda x: x['center'][1])
        sequence.append(current_stage)
        
    return sequence

def format_sequence(seq):
    formatted = []
    for stage in seq:
        names = [p['name'] for p in stage]
        if len(names) > 1:
            formatted.append(f"[{' & '.join(names)}]")
        else:
            formatted.append(names[0])
    return " â†’ ".join(formatted)

# ==========================================
# [Analysis 1] Schematic
# ==========================================
def analyze_schematic(img, model):
    img = resize_image_smart(img)
    w = img.shape[1]
    
    results = model.predict(source=img, save=False, conf=0.05, verbose=False)
    raw_parts = []
    
    for box in results[0].boxes:
        raw_name = model.names[int(box.cls[0])]
        norm_name = normalize_name(raw_name)
        # ìœ„ì¹˜ ë¹„êµìš©ì´ë¯€ë¡œ ì™€ì´ì–´ ì œì™¸
        if norm_name == 'wire' or norm_name == 'leg': continue
        
        coords = box.xyxy[0].tolist()
        raw_parts.append({'name': norm_name, 'box': coords, 'center': get_center(coords), 'conf': float(box.conf[0])})

    parts = []
    raw_parts.sort(key=lambda x: x['conf'], reverse=True)
    for p in raw_parts:
        if not any(calculate_iou(p['box'], k['box']) > 0.1 for k in parts): parts.append(p)

    if parts and not any(p['name'] == 'source' for p in parts):
         leftmost = min(parts, key=lambda p: p['center'][0])
         leftmost['name'] = 'source'

    # ì‹œê°í™”
    for p in parts:
        x1, y1, x2, y2 = map(int, p['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img, p['name'], (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

    sequence = extract_spatial_sequence(parts, w)
    return img, {'parts': parts, 'sequence': sequence, 'seq_str': format_sequence(sequence)}

# ==========================================
# [Analysis 2] Real Board (ë³µêµ¬ëœ ì¸ì‹ ë¡œì§)
# ==========================================
def analyze_real(img, model):
    img = resize_image_smart(img)
    h, w, _ = img.shape
    
    # 1. ì¸ì‹ (Threshold íŠœë‹)
    res = model.predict(source=img, conf=0.10, verbose=False)
    raw_objects = []
    
    for b in res[0].boxes:
        raw_name = model.names[int(b.cls[0])]
        norm_name = normalize_name(raw_name)
        conf = float(b.conf[0])
        
        # [ìˆ˜ì •] ì»¤íŒ¨ì‹œí„° ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì„ê³„ê°’ ì‚´ì§ ìƒí–¥
        if norm_name == 'capacitor' and conf < 0.20: continue 
        if norm_name == 'resistor' and conf < 0.25: continue
        if 'breadboard' in raw_name: continue
        
        coords = b.xyxy[0].tolist()
        raw_objects.append({'name': norm_name, 'box': coords, 'center': get_center(coords), 'conf': conf})

    # 2. ë¶€í’ˆ ë¶„ë¦¬ ë° ì¤‘ë³µ ì œê±°
    parts_candidates = [p for p in raw_objects if p['name'] != 'leg']
    legs = [p for p in raw_objects if p['name'] == 'leg']
    
    parts = solve_overlap_real(parts_candidates) # ì—¬ê¸°ì„œ ê²¹ì¹œ Capacitor ì œê±°ë¨

    # 3. [ë³µêµ¬ë¨] Source ìœ ë¬´ íŒë‹¨ (ì™€ì´ì–´ ìœ„ì¹˜ ê¸°ë°˜)
    TOP_RAIL = h * 0.20; BOTTOM_RAIL = h * 0.80
    has_source = False
    
    if any(p['name'] == 'source' for p in parts): has_source = True
    
    if not has_source:
        # ì™€ì´ì–´ë‚˜ í•€ì´ ì „ì› ë ˆì¼ì— ìˆìœ¼ë©´ Sourceê°€ ìˆë‹¤ê³  íŒë‹¨!
        for p in raw_objects: 
            if p['center'][1] < TOP_RAIL or p['center'][1] > BOTTOM_RAIL:
                if p['name'] == 'wire' or p['name'] == 'leg':
                    has_source = True; break
    
    # Source ê°€ìƒ ë¶€í’ˆ ì¶”ê°€
    if has_source and not any(p['name'] == 'source' for p in parts):
        parts.append({'name': 'source', 'box': [0,0,0,0], 'center': (0,0), 'conf': 1.0})

    # 4. ì‹œê°í™” (SourceëŠ” ë°•ìŠ¤ ê·¸ë¦¬ì§€ ì•Šê³  í…ìŠ¤íŠ¸ë¡œë§Œ í‘œì‹œí•˜ê±°ë‚˜, 0,0 ë°•ìŠ¤ë¼ ì•ˆ ê·¸ë ¤ì§)
    for p in parts:
        if p['name'] == 'wire': continue # ì™€ì´ì–´ëŠ” í™”ë©´ì—ì„œ ìˆ¨ê¹€
        
        color = (0, 255, 0)
        if p['name'] == 'source': color = (0, 255, 255)
        
        if p['box'][2] > 0: # ì‹¤ì œ ë°•ìŠ¤ê°€ ìˆëŠ” ë¶€í’ˆë§Œ ê·¸ë¦¬ê¸°
            x1, y1, x2, y2 = map(int, p['box'])
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)
            cv2.putText(img, p['name'].upper(), (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        elif p['name'] == 'source':
            # ê°€ìƒ SourceëŠ” í™”ë©´ ì¢Œìƒë‹¨ì— í‘œì‹œ
            cv2.putText(img, "POWER DETECTED", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

    # 5. ìœ„ì¹˜ ê¸°ë°˜ ìˆœì„œ ì¶”ì¶œ (ì™€ì´ì–´ ì œì™¸í•˜ê³  ë¶€í’ˆë§Œ)
    main_parts = [p for p in parts if p['name'] != 'wire']
    sequence = extract_spatial_sequence(main_parts, w)
    
    return img, {'parts': parts, 'sequence': sequence, 'seq_str': format_sequence(sequence)}

# ==========================================
# [Main UI]
# ==========================================
st.title("ğŸ§  BrainBoard V67: Robust Hybrid")
st.markdown("### ğŸ“ ì¸ì‹ë¥  ë³µêµ¬ + ì§ê´€ì  ìœ„ì¹˜ ë¹„êµ")

@st.cache_resource
def load_models():
    gc.collect()
    return YOLO(REAL_MODEL_PATH), YOLO(MODEL_SYM_PATH)

try:
    model_real, model_sym = load_models()
    st.sidebar.success("âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
except: st.stop()

col1, col2 = st.columns(2)
ref_file = col1.file_uploader("1. íšŒë¡œë„", type=['jpg', 'png', 'jpeg'])
tgt_file = col2.file_uploader("2. ì‹¤ë¬¼ ì‚¬ì§„", type=['jpg', 'png', 'jpeg'])

if ref_file and tgt_file:
    ref_image = Image.open(ref_file)
    tgt_image = Image.open(tgt_file)
    ref_cv = cv2.cvtColor(np.array(ref_image), cv2.COLOR_RGB2BGR)
    tgt_cv = cv2.cvtColor(np.array(tgt_image), cv2.COLOR_RGB2BGR)

    if st.button("ğŸš€ ë¶„ì„ ì‹¤í–‰"):
        gc.collect()
        with st.spinner("ë¶€í’ˆ ì¸ì‹ ë° ë°°ì¹˜ ë¶„ì„ ì¤‘..."):
            
            res_ref_img, ref_data = analyze_schematic(ref_cv.copy(), model_sym)
            res_tgt_img, tgt_data = analyze_real(tgt_cv.copy(), model_real)

            # 1. BOM Check
            st.subheader("1. ë¶€í’ˆ ê°œìˆ˜ í™•ì¸")
            ref_counts = defaultdict(int)
            tgt_counts = defaultdict(int)
            for p in ref_data['parts']: ref_counts[p['name']] += 1
            for p in tgt_data['parts']: tgt_counts[p['name']] += 1
            
            # wireëŠ” ê°œìˆ˜ ë¹„êµì—ì„œ ì œì™¸
            all_keys = set(ref_counts.keys()) | set(tgt_counts.keys()) - {'wire'}
            
            bom_match = True
            bom_data = []
            for k in all_keys:
                r = ref_counts[k]; t = tgt_counts[k]
                status = "âœ… ì¼ì¹˜" if r == t else "âŒ ë¶ˆì¼ì¹˜"
                bom_data.append({"ë¶€í’ˆëª…": k.upper(), "íšŒë¡œë„": r, "ì‹¤ë¬¼": t, "ìƒíƒœ": status})
                if r != t: bom_match = False
            st.table(bom_data)

            # 2. Sequence Check
            st.subheader("2. ë°°ì¹˜ ìˆœì„œ ë¹„êµ (Left -> Right)")
            
            st.info(f"ğŸ“œ **íšŒë¡œë„ ìˆœì„œ:** {ref_data['seq_str']}")
            st.info(f"ğŸ“¸ **ì‹¤ë¬¼ ë°°ì¹˜:** {tgt_data['seq_str']}")
            
            # ë‹¨ìˆœ ë¬¸ìì—´ ë¹„êµ ëŒ€ì‹  ë‹¨ê³„ë³„ ë¹„êµ
            ref_seq = ref_data['sequence']
            tgt_seq = tgt_data['sequence']
            
            is_seq_match = True
            
            # ë‹¨ê³„ ìˆ˜ê°€ ë‹¤ë¥´ë©´ ê¸¸ì´ ë¹„êµ
            if len(ref_seq) != len(tgt_seq):
                 st.warning("âš ï¸ ë°°ì¹˜ ë‹¨ê³„(Column) ìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤. (íšŒë¡œë„ì™€ ì‹¤ë¬¼ì˜ ê°„ê²© ì°¨ì´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            
            # ê°€ëŠ¥í•œ ë²”ìœ„ ë‚´ì—ì„œ ë¹„êµ
            min_len = min(len(ref_seq), len(tgt_seq))
            for i in range(min_len):
                r_names = sorted([p['name'] for p in ref_seq[i]])
                t_names = sorted([p['name'] for p in tgt_seq[i]])
                
                if r_names == t_names:
                    st.success(f"âœ… Step {i+1}: {r_names} - ì¼ì¹˜")
                else:
                    st.error(f"âŒ Step {i+1}: ë¶ˆì¼ì¹˜ (íšŒë¡œë„:{r_names} vs ì‹¤ë¬¼:{t_names})")
                    is_seq_match = False

            if is_seq_match and bom_match and (len(ref_seq) == len(tgt_seq)):
                st.success("ğŸ‰ **ì™„ë²½í•©ë‹ˆë‹¤! ë¶€í’ˆ êµ¬ì„±ê³¼ ë°°ì¹˜ ìˆœì„œê°€ ì¼ì¹˜í•©ë‹ˆë‹¤.**")
                st.balloons()
            
            st.image(cv2.cvtColor(res_ref_img, cv2.COLOR_BGR2RGB), caption="íšŒë¡œë„ ë¶„ì„", use_column_width=True)
            st.image(cv2.cvtColor(res_tgt_img, cv2.COLOR_BGR2RGB), caption="ì‹¤ë¬¼ ë¶„ì„ (ì¸ì‹ ë³µêµ¬ë¨)", use_column_width=True)
            
            del res_ref_img, res_tgt_img
            gc.collect()
