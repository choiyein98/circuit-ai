import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
from PIL import Image

# ==========================================
# [ì„¤ì • ë° ìƒìˆ˜]
# ==========================================
st.set_page_config(page_title="BrainBoard V44", layout="wide")

MODEL_REAL_PATH = 'best.pt'      
MODEL_SYM_PATH = 'symbol.pt'     

# ì—°ê²° ê°ì§€ ê±°ë¦¬ (í”½ì…€ ë‹¨ìœ„) - ì´ ê±°ë¦¬ ì•ˆì— í•€ë¼ë¦¬ ìˆìœ¼ë©´ ì—°ê²°ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
CONNECTION_THRESHOLD = 90  

# ==========================================
# [Helper Functions]
# ==========================================
def calculate_iou(box1, box2):
    x1, y1, x2, y2 = max(box1[0], box2[0]), max(box1[1], box2[1]), min(box1[2], box2[2]), min(box1[3], box2[3])
    inter = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - inter
    return inter / union if union > 0 else 0

def solve_overlap(parts, distance_threshold=40):
    if not parts: return []
    parts.sort(key=lambda x: x.get('conf', 0), reverse=True)
    final_parts = []
    for current in parts:
        is_duplicate = False
        for kept in final_parts:
            iou = calculate_iou(current['box'], kept['box'])
            cx1, cy1 = current['center']
            cx2, cy2 = kept['center']
            dist = math.sqrt((cx1-cx2)**2 + (cy1-cy2)**2)
            if iou > 0.3 or dist < distance_threshold:
                is_duplicate = True; break
        if not is_duplicate:
            final_parts.append(current)
    return final_parts

def get_center(box):
    return ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)

# ==========================================
# [ë¶„ì„ í•¨ìˆ˜ 1: íšŒë¡œë„ (Schematic)]
# ==========================================
def analyze_schematic(img, model):
    results = model.predict(source=img, save=False, conf=0.1, verbose=False)
    boxes = results[0].boxes
    
    raw_parts = []
    for box in boxes:
        cls_id = int(box.cls[0])
        name = model.names[cls_id].lower()
        conf = float(box.conf[0])
        coords = box.xyxy[0].tolist()
        center = get_center(coords)
        
        base_name = name.split('_')[0].split(' ')[0]
        if base_name in ['vdc', 'vsource', 'battery', 'voltage']: base_name = 'source'
        if base_name in ['cap', 'c', 'capacitor']: base_name = 'capacitor'
        if base_name in ['res', 'r', 'resistor']: base_name = 'resistor'
        
        raw_parts.append({'name': base_name, 'box': coords, 'center': center, 'conf': conf})

    clean_parts = solve_overlap(raw_parts, distance_threshold=30)
    
    # íšŒë¡œë„ ì‹œê°í™”
    for part in clean_parts:
        name = part['name']
        x1, y1, x2, y2 = map(int, part['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img, name, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
    summary = {'total': len(clean_parts), 'details': {}}
    for part in clean_parts:
        n = part['name']
        summary['details'][n] = summary['details'].get(n, 0) + 1
        
    return img, summary

# ==========================================
# [ë¶„ì„ í•¨ìˆ˜ 2: ì‹¤ë¬¼ (Real Board) - ë‹¤ë¦¬ ì¤‘ì‹¬ ì‹œê°í™”]
# ==========================================
def analyze_real(img, model):
    height, width, _ = img.shape
    
    # 1. ëª¨ë¸ ì˜ˆì¸¡
    results = model.predict(source=img, save=False, conf=0.15, verbose=False)
    boxes = results[0].boxes

    # 2. ê°ì²´ ìˆ˜ì§‘
    components = [] 
    legs = []       
    
    for box in boxes:
        cls_id = int(box.cls[0])
        name = model.names[cls_id].lower()
        coords = box.xyxy[0].tolist()
        center = get_center(coords)
        
        # ë„ˆë¬´ ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
        if (coords[2]-coords[0]) * (coords[3]-coords[1]) < (width * height * 0.001): continue

        if any(x in name for x in ['pin', 'leg', 'lead', 'wire']):
            # ë‹¤ë¦¬(Pin)ëŠ” ì¢Œí‘œë§Œ ì €ì¥
            legs.append({'center': center, 'box': coords, 'type': 'pin'})
        elif 'breadboard' in name:
            continue
        else:
            # ëª¸í†µ(Body) ì €ì¥
            components.append({
                'name': name, 'box': coords, 'center': center, 
                'my_legs': [], 'is_active': False
            })

    components = solve_overlap(components, distance_threshold=50)

    # 3. [ê°€ìƒ ì „ì› ë ˆì¼] í‘œì‹œ
    top_rail_y = height * 0.20
    bottom_rail_y = height * 0.80
    
    cv2.rectangle(img, (0, 0), (width, int(top_rail_y)), (0, 255, 255), 1) 
    cv2.rectangle(img, (0, int(bottom_rail_y)), (width, height), (0, 255, 255), 1) 
    
    # 4. [ë‹¤ë¦¬ í• ë‹¹] ëª¸í†µê³¼ ê°€ì¥ ê°€ê¹Œìš´ ë‹¤ë¦¬ë“¤ì„ ì°¾ì•„ì„œ ì—°ê²°
    for comp in components:
        bw = comp['box'][2] - comp['box'][0]
        bh = comp['box'][3] - comp['box'][1]
        diag = math.sqrt(bw**2 + bh**2)
        search_radius = diag * 0.8  # ë¶€í’ˆ í¬ê¸° ë°˜ê²½ ë‚´ ê²€ìƒ‰

        for leg in legs:
            dist = math.sqrt((leg['center'][0]-comp['center'][0])**2 + (leg['center'][1]-comp['center'][1])**2)
            if dist < search_radius:
                comp['my_legs'].append(leg)
        
        # ë‹¤ë¦¬ê°€ ì¸ì‹ ì•ˆ ëì„ ê²½ìš°, ëª¸í†µ ì–‘ ëì„ ê°€ìƒì˜ ë‹¤ë¦¬ë¡œ ì„¤ì •
        if len(comp['my_legs']) < 2:
            x1, y1, x2, y2 = comp['box']
            if bw > bh: # ê°€ë¡œí˜•
                comp['my_legs'] = [{'center':(x1, (y1+y2)/2)}, {'center':(x2, (y1+y2)/2)}]
            else: # ì„¸ë¡œí˜•
                comp['my_legs'] = [{'center':((x1+x2)/2, y1)}, {'center':((x1+x2)/2, y2)}]

    # 5. [ì „ë¥˜ íë¦„ ì‹œë®¬ë ˆì´ì…˜]
    # (A) ì „ì› ì†ŒìŠ¤ ì°¾ê¸° (ë ˆì¼ì— ë‹¿ì€ ë‹¤ë¦¬)
    active_legs = [] 
    
    for comp in components:
        for leg in comp['my_legs']:
            ly = leg['center'][1]
            if ly < top_rail_y or ly > bottom_rail_y:
                comp['is_active'] = True
                active_legs.append(leg['center'])
    
    # (B) ì „ë¥˜ ì „íŒŒ (ê±°ë¦¬ ê¸°ë°˜)
    changed = True
    while changed:
        changed = False
        for comp in components:
            if comp['is_active']: 
                # ë‚´ê°€ ì¼œì¡Œìœ¼ë©´ ë‚´ ë‹¤ë¦¬ë“¤ë„ ì „ì› ì†ŒìŠ¤ê°€ ë¨
                for leg in comp['my_legs']:
                    if leg['center'] not in active_legs:
                        active_legs.append(leg['center'])
                        changed = True
                continue
            
            # ë‚´ê°€ êº¼ì ¸ ìˆìœ¼ë©´ ì£¼ë³€ì— í™œì„± ë‹¤ë¦¬ê°€ ìˆëŠ”ì§€ í™•ì¸
            for my_leg in comp['my_legs']:
                for active_pt in active_legs:
                    dist = math.sqrt((my_leg['center'][0]-active_pt[0])**2 + (my_leg['center'][1]-active_pt[1])**2)
                    if dist < CONNECTION_THRESHOLD:
                        comp['is_active'] = True
                        changed = True
                        break 
                if comp['is_active']: break

    # 6. [ì‹œê°í™”] ëª¸í†µì€ ì–‡ê²Œ, ë‹¤ë¦¬ëŠ” ì ìœ¼ë¡œ!
    summary = {'total': 0, 'on': 0, 'off': 0, 'details': {}}
    
    for comp in components:
        name = comp['name']
        x1, y1, x2, y2 = map(int, comp['box'])
        center = comp['center']

        if comp['is_active']:
            color = (0, 255, 0) # ì´ˆë¡ (ON)
            status = "ON"
            summary['on'] += 1
        else:
            color = (0, 0, 255) # ë¹¨ê°• (OFF)
            status = "OFF"
            summary['off'] += 1
            
        summary['total'] += 1
        
        # 1) ëª¸í†µ ë°•ìŠ¤ëŠ” ì–‡ê²Œ í‘œì‹œ (ì‹ë³„ìš©)
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 1)
        
        # 2) [í•µì‹¬] ë‹¤ë¦¬ ìœ„ì¹˜ì— 'ì ' ì°ê³  ì—°ê²°ì„  ê·¸ë¦¬ê¸°
        for leg in comp['my_legs']:
            lx, ly = map(int, leg['center'])
            
            # ëª¸í†µ ì¤‘ì‹¬ì—ì„œ ë‹¤ë¦¬ê¹Œì§€ ì„  ê·¸ë¦¬ê¸°
            cv2.line(img, (int(center[0]), int(center[1])), (lx, ly), color, 2)
            
            # ë‹¤ë¦¬ ëë¶€ë¶„ì— ì› ê·¸ë¦¬ê¸° (ì—¬ê¸°ê°€ ì—°ê²° í¬ì¸íŠ¸)
            cv2.circle(img, (lx, ly), 8, color, -1) 
            cv2.circle(img, (lx, ly), 8, (255, 255, 255), 2) # í° í…Œë‘ë¦¬

        # 3) ìƒíƒœ í…ìŠ¤íŠ¸
        cv2.putText(img, status, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        base_name = name.split('_')[0]
        summary['details'][base_name] = summary['details'].get(base_name, 0) + 1

    return img, summary

# ==========================================
# [Main UI Execution] - ì—¬ê¸°ê°€ ìˆì–´ì•¼ í™”ë©´ì´ ë‚˜ì˜µë‹ˆë‹¤!
# ==========================================
st.title("ğŸ§  BrainBoard V44: AI Circuit Verifier")
st.markdown("### PSpice íšŒë¡œë„ì™€ ì‹¤ì œ ë¸Œë ˆë“œë³´ë“œ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

@st.cache_resource
def load_models():
    return YOLO(MODEL_REAL_PATH), YOLO(MODEL_SYM_PATH)

try:
    model_real, model_sym = load_models()
    st.sidebar.success("âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
except Exception as e:
    st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    st.stop()

# íŒŒì¼ ì—…ë¡œë” ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns(2)
ref_file = col1.file_uploader("íšŒë¡œë„(Schematic) ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])
tgt_file = col2.file_uploader("ì‹¤ë¬¼(Real Board) ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])

if ref_file and tgt_file:
    # ì´ë¯¸ì§€ ë¡œë“œ
    ref_image = Image.open(ref_file)
    tgt_image = Image.open(tgt_file)
    
    # OpenCV í¬ë§·ìœ¼ë¡œ ë³€í™˜ (RGB -> BGR)
    ref_cv = cv2.cvtColor(np.array(ref_image), cv2.COLOR_RGB2BGR)
    tgt_cv = cv2.cvtColor(np.array(tgt_image), cv2.COLOR_RGB2BGR)

    if st.button("ğŸš€ íšŒë¡œ ê²€ì¦ ì‹œì‘ (Analyze)"):
        with st.spinner("AIê°€ íšŒë¡œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # ë¶„ì„ ìˆ˜í–‰
            res_ref_img, ref_data = analyze_schematic(ref_cv.copy(), model_sym)
            res_tgt_img, tgt_data = analyze_real(tgt_cv.copy(), model_real)

            # ê²°ê³¼ ë¦¬í¬íŠ¸ í‘œì‹œ
            st.divider()
            
            # 1. ê°œìˆ˜ ë¹„êµ
            st.markdown("#### 1. ë¶€í’ˆ ê°œìˆ˜ ì¼ì¹˜ ì—¬ë¶€")
            all_parts = set(ref_data['details'].keys()) | set(tgt_data['details'].keys())
            match_count = True
            for part in all_parts:
                c1 = ref_data['details'].get(part, 0)
                c2 = tgt_data['details'].get(part, 0)
                if c1 == c2:
                    st.write(f"- âœ… {part}: {c1}ê°œ ì¼ì¹˜")
                else:
                    st.write(f"- âš ï¸ {part}: íšŒë¡œë„ {c1}ê°œ vs ì‹¤ë¬¼ {c2}ê°œ")
                    match_count = False

            # 2. ì—°ê²° ìƒíƒœ ë¹„êµ
            st.markdown("#### 2. ì „ê¸°ì  ì—°ê²° ìƒíƒœ (ON/OFF)")
            if tgt_data['off'] == 0:
                st.success(f"ğŸ‰ Perfect! ëª¨ë“  ë¶€í’ˆ({tgt_data['total']}ê°œ)ì´ ì •ìƒ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.error(f"âŒ {tgt_data['off']}ê°œì˜ ë¶€í’ˆì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ë¹¨ê°„ìƒ‰ ì  í™•ì¸)")

            # 3. ì´ë¯¸ì§€ ì¶œë ¥ (BGR -> RGB ë³€í™˜ í•„ìˆ˜)
            st.image(cv2.cvtColor(res_ref_img, cv2.COLOR_BGR2RGB), caption="PSpice íšŒë¡œë„ ë¶„ì„", use_column_width=True)
            st.image(cv2.cvtColor(res_tgt_img, cv2.COLOR_BGR2RGB), caption="ì‹¤ë¬¼ ë³´ë“œ ë¶„ì„ (ì  = ë‹¤ë¦¬ ìœ„ì¹˜)", use_column_width=True)
