import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
from PIL import Image

# ==========================================
# [1. ì„¤ì • ë° ê²½ë¡œ]
# ==========================================
st.set_page_config(page_title="BrainBoard V53: Hybrid Final", layout="wide")

MODEL_REAL_PATH = 'best(3).pt'
MODEL_SYM_PATH = 'symbol.pt'

# ì‹¤ë¬¼ ë¶€í’ˆë³„ ì‹ ë¢°ë„ ì„ê³„ê°’
CONFIDENCE_MAP_REAL = {
    'led': 0.50,
    'capacitor': 0.40,
    'voltage': 0.25,
    'source': 0.25,
    'resistor': 0.65, # ì‹¤ë¬¼ ì €í•­ì€ ì—„ê²©í•˜ê²Œ
    'wire': 0.25,
    'default': 0.30
}

# ==========================================
# [2. í•µì‹¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜]
# ==========================================
def calculate_iou(box1, box2):
    x1, y1, x2, y2 = max(box1[0], box2[0]), max(box1[1], box2[1]), min(box1[2], box2[2]), min(box1[3], box2[3])
    inter = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - inter
    return inter / union if union > 0 else 0

def get_center(box):
    return ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)

def normalize_name(raw_name):
    name = raw_name.lower().strip()
    if any(x in name for x in ['res', 'r']): return 'RESISTOR'
    if any(x in name for x in ['cap', 'c']): return 'CAPACITOR'
    if any(x in name for x in ['v', 'volt', 'batt', 'source', 'vdc']): return 'SOURCE'
    if any(x in name for x in ['pin', 'leg', 'lead']): return 'PIN'
    if 'wire' in name: return 'WIRE'
    return 'OTHER'

# [V52 í•„í„°] ì™€ì´ì–´ ì˜¤ì¸ì‹ ë°©ì§€ (ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ì²´í¬)
def fix_misclassified_wire(box, name):
    x1, y1, x2, y2 = box
    w, h = x2 - x1, y2 - y1
    if w == 0 or h == 0: return name
    ratio = max(w, h) / min(w, h)
    # ì €í•­ ëª¸ì²´ ì¹˜ê³ ëŠ” ë„ˆë¬´ ê¸¸ì­‰í•˜ë©´ 100% ì™€ì´ì–´ì…ë‹ˆë‹¤.
    if name == 'RESISTOR' and ratio > 6.0:
        return 'WIRE'
    return name

# [V53 ê°œì„ ] ì¤‘ë³µ ì œê±° ê¸°ì¤€ ë¶„ë¦¬
def solve_overlap(parts, is_schematic=False):
    if not parts: return []
    
    if is_schematic:
        # íšŒë¡œë„: ë©´ì  ì‘ì€ ê²ƒ ìš°ì„  (ê¸°ì¡´ ì˜ ë˜ë˜ V35 ë¡œì§)
        parts.sort(key=lambda x: (x['box'][2]-x['box'][0]) * (x['box'][3]-x['box'][1]))
        dist_thresh = 20 # ë¶€í’ˆê³¼ í…ìŠ¤íŠ¸ê°€ ë¶™ì–´ìˆìœ¼ë¯€ë¡œ ì•„ì£¼ ì¢ê²Œ ì„¤ì •
    else:
        # ì‹¤ë¬¼: ì‹ ë¢°ë„ ë†’ì€ ê²ƒ ìš°ì„  (V48 ë¡œì§)
        parts.sort(key=lambda x: x.get('conf', 0), reverse=True)
        dist_thresh = 80 # ê·¸ë¦¼ìë‚˜ ë‹¤ë¦¬ ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë„“ê²Œ ì„¤ì •

    final = []
    for curr in parts:
        is_dup = False
        for k in final:
            dist = math.sqrt((curr['center'][0]-k['center'][0])**2 + (curr['center'][1]-k['center'][1])**2)
            if dist < dist_thresh:
                is_dup = True; break
        if not is_dup:
            final.append(curr)
    return final

# ==========================================
# [3. ë¶„ì„ ì—”ì§„]
# ==========================================
def analyze_schematic(img, model):
    # ê¸°ì¡´ì— ì˜ ì¡íˆë˜ ì„¤ì •ê°’ ê·¸ëŒ€ë¡œ ìœ ì§€
    res = model.predict(source=img, conf=0.15, verbose=False)
    raw = []
    for b in res[0].boxes:
        name = normalize_name(model.names[int(b.cls[0])])
        if name == 'OTHER': continue
        coords = b.xyxy[0].tolist()
        raw.append({'name': name, 'box': coords, 'center': get_center(coords)})
    
    clean = solve_overlap(raw, is_schematic=True)
    
    # ì „ì› ë³´ì •
    if clean and not any(p['name'] == 'SOURCE' for p in clean):
        min(clean, key=lambda p: p['center'][0])['name'] = 'SOURCE'

    summary = {}
    for p in clean:
        x1, y1, x2, y2 = map(int, p['box'])
        color = (255, 0, 0) if p['name'] == 'SOURCE' else (0, 0, 255)
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
        cv2.putText(img, p['name'], (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        summary[p['name']] = summary.get(p['name'], 0) + 1
    return img, summary

def analyze_real(img, model):
    res = model.predict(source=img, conf=0.10, verbose=False)
    raw = []
    for b in res[0].boxes:
        name = model.names[int(b.cls[0])].lower()
        conf = float(b.conf[0])
        
        # ì‹ ë¢°ë„ í•„í„°
        thresh = CONFIDENCE_MAP_REAL.get('default')
        for k in CONFIDENCE_MAP_REAL:
            if k in name: thresh = CONFIDENCE_MAP_REAL[k]; break
        if conf < thresh: continue
        
        coords = b.xyxy[0].tolist()
        norm_name = normalize_name(name)
        # [V52] ì™€ì´ì–´ í•„í„° ì ìš©
        norm_name = fix_misclassified_wire(coords, norm_name)
        
        if norm_name in ['OTHER', 'PIN']: continue # PINì€ í™”ë©´ì—” ë³´ì—¬ë„ ê°œìˆ˜ì—ì„œ ëºŒ
        
        raw.append({'name': norm_name, 'box': coords, 'center': get_center(coords), 'conf': conf})

    clean = solve_overlap(raw, is_schematic=False)
    
    summary = {}
    for b in clean:
        x1, y1, x2, y2 = map(int, b['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)
        cv2.putText(img, b['name'], (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        if b['name'] != 'WIRE':
            summary[b['name']] = summary.get(b['name'], 0) + 1
            
    # ì™€ì´ì–´ê°€ ë§ìœ¼ë©´ ì „ì› 1ê°œ ê°€ìƒ ì¶”ê°€ (ì‚¬ìš©ì ë¡œì§ ìœ ì§€)
    if sum(1 for b in clean if b['name'] == 'WIRE') >= 2:
        summary['SOURCE'] = summary.get('SOURCE', 0) + 1
        
    return img, summary

# ==========================================
# [4. UI ë° ì‹¤í–‰]
# ==========================================
st.title("ğŸ§  BrainBoard V53: Perfect Hybrid")

@st.cache_resource
def load_models():
    return YOLO(MODEL_REAL_PATH), YOLO(MODEL_SYM_PATH)

model_real, model_sym = load_models()

col1, col2 = st.columns(2)
ref_file = col1.file_uploader("1. íšŒë¡œë„ ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])
tgt_file = col2.file_uploader("2. ì‹¤ë¬¼ ì‚¬ì§„ ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])

if ref_file and tgt_file:
    if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘"):
        ref_cv = cv2.cvtColor(np.array(Image.open(ref_file)), cv2.COLOR_RGB2BGR)
        tgt_cv = cv2.cvtColor(np.array(Image.open(tgt_file)), cv2.COLOR_RGB2BGR)

        res_ref, data_ref = analyze_schematic(ref_cv.copy(), model_sym)
        res_tgt, data_tgt = analyze_real(tgt_cv.copy(), model_real)

        st.divider()
        all_parts = set(data_ref.keys()) | set(data_tgt.keys())
        for p in sorted(all_parts):
            r, t = data_ref.get(p, 0), data_tgt.get(p, 0)
            if r == t: st.success(f"âœ… {p.upper()} ì¼ì¹˜: {r}ê°œ")
            else: st.error(f"âš ï¸ {p.upper()} ë¶ˆì¼ì¹˜: íšŒë¡œë„ {r}ê°œ vs ì‹¤ë¬¼ {t}ê°œ")

        st.image(cv2.cvtColor(res_ref, cv2.COLOR_BGR2RGB), caption="íšŒë¡œë„ ë¶„ì„ (ê¸°ì¡´ ì„±ëŠ¥ ë³µêµ¬)", use_column_width=True)
        st.image(cv2.cvtColor(res_tgt, cv2.COLOR_BGR2RGB), caption="ì‹¤ë¬¼ ë¶„ì„ (ì™€ì´ì–´ ì˜¤ì¸ì‹ ì œê±°)", use_column_width=True)
