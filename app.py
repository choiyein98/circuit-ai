import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
from PIL import Image

# ==========================================
# [ì„¤ì •] V49: "ë†“ì¹˜ëŠ” ë¶€í’ˆ ì—†ê²Œ í•˜ë¼" (Recall ìš°ì„ )
# ==========================================
st.set_page_config(page_title="BrainBoard V49: Recall Boost", layout="wide")

MODEL_REAL_PATH = 'best(3).pt'  # ì‹¤ë¬¼ ëª¨ë¸
MODEL_SYM_PATH = 'symbol.pt'    # íšŒë¡œë„ ëª¨ë¸

PROXIMITY_THRESHOLD = 100
IOU_THRESHOLD = 0.3

# [í•µì‹¬ ìˆ˜ì • 1] ì €í•­ ê¸°ì¤€ì„ ë‹¤ì‹œ ë‚®ì¶¤ (0.65 -> 0.30)
# ì´ì œ ì¡°ê¸ˆë§Œ ì €í•­ ê°™ì•„ ë³´ì—¬ë„ ë¬´ì¡°ê±´ ì¡ìŠµë‹ˆë‹¤.
CONFIDENCE_MAP = {
    'led': 0.50,
    'capacitor': 0.40,
    'voltage': 0.25,
    'source': 0.25,
    'resistor': 0.30,  # [í•˜í–¥ ì¡°ì •] ìˆ¨ì€ ì €í•­ ì°¾ê¸° ìœ„í•´ ë¬¸í„± ë‚®ì¶¤
    'wire': 0.25,
    'default': 0.25
}

# ==========================================
# [Helper Functions]
# ==========================================
def calculate_iou(box1, box2):
    x1, y1, x2, y2 = max(box1[0], box2[0]), max(box1[1], box2[1]), min(box1[2], box2[2]), min(box1[3], box2[3])
    inter = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - inter
    return inter / union if union > 0 else 0

def non_max_suppression(boxes, iou_thresh):
    if not boxes: return []
    kept = []
    for curr in boxes:
        is_dup = False
        for k in kept:
            if calculate_iou(curr['box'], k['box']) > iou_thresh: is_dup = True; break
        if not is_dup: kept.append(curr)
    return kept

def get_center(box):
    return ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)

def is_near_box(point, box, margin=50):
    px, py = point
    return (box[0]-margin) < px < (box[2]+margin) and (box[1]-margin) < py < (box[3]+margin)

# [í•µì‹¬ ìˆ˜ì • 2] í¬ê¸° í•„í„° ë” ì™„í™” (ì‘ì€ ì €í•­ë„ í†µê³¼)
def is_valid_size(box, img_w, img_h):
    x1, y1, x2, y2 = box
    w = x2 - x1
    h = y2 - y1
    area = w * h
    img_area = img_w * img_h
    # 0.05% í¬ê¸°ë§Œ ë˜ì–´ë„ í†µê³¼ (ì•„ì£¼ ì‘ì€ ë¶€í’ˆ í—ˆìš©)
    if area < img_area * 0.0005: return False 
    return True

# ë¹„ìœ¨ í•„í„° ì‚­ì œ (ë‹¤ë¦¬ê°€ ê¸´ ì €í•­ì„ ì™€ì´ì–´ë¡œ ì°©ê°í•´ì„œ ì§€ìš°ëŠ” í˜„ìƒ ë°©ì§€)

def is_intersecting(boxA, boxB):
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])
    return max(0, xB - xA) * max(0, yB - yA) > 0

def solve_overlap(parts, distance_threshold=80):
    if not parts: return []
    if 'conf' in parts[0]:
        parts.sort(key=lambda x: x['conf'], reverse=True)
    
    final_parts = []
    for current in parts:
        is_duplicate = False
        for kept in final_parts:
            iou = calculate_iou(current['box'], kept['box'])
            cx1, cy1 = current['center']
            cx2, cy2 = kept['center']
            dist = math.sqrt((cx1-cx2)**2 + (cy1-cy2)**2)
            
            if iou > 0.1 or dist < distance_threshold:
                is_duplicate = True
                break
        if not is_duplicate:
            final_parts.append(current)
    return final_parts

# ==========================================
# [ë¶„ì„ 1] íšŒë¡œë„ (Schematic) - í˜„ìƒ ìœ ì§€
# ==========================================
def analyze_schematic(img, model):
    # íšŒë¡œë„ëŠ” ì˜ ë˜ë¯€ë¡œ 5% ìœ ì§€
    results = model.predict(source=img, save=False, conf=0.05, verbose=False)
    boxes = results[0].boxes
    raw_parts = []
    
    for box in boxes:
        cls_id = int(box.cls[0])
        name = model.names[cls_id].lower()
        conf = float(box.conf[0])
        coords = box.xyxy[0].tolist()
        center = get_center(coords)
        
        base_name = name.split('_')[0].split(' ')[0]
        if base_name in ['vdc', 'vsource', 'battery', 'voltage']: base_name = 'source'
        if base_name in ['cap', 'c', 'capacitor']: base_name = 'capacitor'
        if base_name in ['res', 'r', 'resistor']: base_name = 'resistor'
        
        raw_parts.append({'name': base_name, 'box': coords, 'center': center, 'conf': conf})

    clean_parts = solve_overlap(raw_parts)

    # ì „ì› ë³´ì •
    if clean_parts:
        has_source = any(p['name'] == 'source' for p in clean_parts)
        if not has_source:
            leftmost_part = min(clean_parts, key=lambda p: p['center'][0])
            leftmost_part['name'] = 'source'

    summary = {'total': 0, 'details': {}}
    for part in clean_parts:
        name = part['name']
        x1, y1, x2, y2 = map(int, part['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img, f"{name}", (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
        summary['total'] += 1
        if name not in summary['details']: summary['details'][name] = 0
        summary['details'][name] += 1
        
    return img, summary

# ==========================================
# [ë¶„ì„ 2] ì‹¤ë¬¼ ë³´ë“œ (Real) - ìˆ¨ì€ ì €í•­ ì°¾ê¸°
# ==========================================
def analyze_real(img, model):
    height, width, _ = img.shape
    # conf=0.1 : 10% í™•ë¥ ì´ë¼ë„ ìˆìœ¼ë©´ ì¼ë‹¨ í›„ë³´ë¡œ ì˜¬ë¦¼
    results = model.predict(source=img, save=False, conf=0.1, verbose=False)
    boxes = results[0].boxes

    raw_objects = {'body': [], 'leg': [], 'plus': [], 'minus': []}
    
    for box in boxes:
        cls_id = int(box.cls[0])
        name = model.names[cls_id].lower()
        conf = float(box.conf[0])
        
        # 1. ì‹ ë¢°ë„ í•„í„° (ì—¬ê¸°ì„œ ê±¸ëŸ¬ì§)
        threshold = CONFIDENCE_MAP.get('default')
        for key in CONFIDENCE_MAP:
            if key in name: threshold = CONFIDENCE_MAP[key]; break
        
        if conf < threshold: continue
        if name in ['breadboard', 'text', 'hole']: continue
        
        coords = box.xyxy[0].tolist()
        
        # 2. í¬ê¸° í•„í„° (ë„ˆë¬´ ì‘ì€ ê²ƒë§Œ ì œê±°)
        if not is_valid_size(coords, width, height): continue
        
        # [ì‚­ì œ] ë¹„ìœ¨ í•„í„° ì œê±° (ê¸¸ì­‰í•œ ì €í•­ë„ í†µê³¼ì‹œí‚¤ê¸° ìœ„í•¨)

        item = {'name': name, 'box': coords, 'center': get_center(coords), 'conf': conf}
        
        if any(x in name for x in ['pin', 'leg', 'lead']): raw_objects['leg'].append(item)
        elif any(x in name for x in ['plus', 'positive', 'vcc', '5v']): raw_objects['plus'].append(item)
        elif any(x in name for x in ['minus', 'negative', 'gnd']): raw_objects['minus'].append(item)
        else: raw_objects['body'].append(item)

    clean_bodies = solve_overlap(raw_objects['body'], distance_threshold=80)

    # ì‹œê°í™”
    virtual_rails = {'plus': [], 'minus': []}
    virtual_rails['plus'].append({'box': [0, 0, width, height*0.20], 'type': 'VCC'})
    virtual_rails['minus'].append({'box': [0, height*0.80, width, height], 'type': 'GND'})
    
    for r in virtual_rails['plus']:
        cv2.rectangle(img, (0, 0), (width, int(height*0.20)), (0, 255, 255), 1)
    for r in virtual_rails['minus']:
        cv2.rectangle(img, (0, int(height*0.80)), (width, height), (255, 200, 0), 1)

    components = []
    for body in clean_bodies:
        components.append({'body': body, 'is_active': True})

    summary = {'total': 0, 'on': 0, 'off': 0, 'details': {}}
    
    # ì™€ì´ì–´ê°€ 2ê°œ ì´ìƒì´ë©´ ì „ì› ì—°ê²°ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
    wire_count = sum(1 for c in components if 'wire' in c['body']['name'])
    if wire_count >= 2:
        summary['details']['source'] = {'count': 1}

    for comp in components:
        name = comp['body']['name']
        color = (0, 255, 0)
        status = f"{name} {comp['body']['conf']:.2f}"
        
        x1, y1, x2, y2 = map(int, comp['body']['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)
        
        label_size, baseline = cv2.getTextSize(status, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
        y_label = max(y1, label_size[1] + 10)
        cv2.rectangle(img, (x1, y_label - label_size[1] - 10), (x1 + label_size[0], y_label + baseline - 10), color, -1)
        cv2.putText(img, status, (x1, y_label - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
        
        summary['total'] += 1
        summary['on'] += 1

        base_name = name.split('_')[0].split(' ')[0]
        if base_name in ['voltage', 'source', 'battery']: base_name = 'source'
        if base_name in ['cap', 'c', 'capacitor']: base_name = 'capacitor'
        if base_name in ['res', 'r', 'resistor']: base_name = 'resistor'
        
        if base_name not in summary['details']: summary['details'][base_name] = {'count': 0}
        summary['details'][base_name]['count'] += 1
        
    return img, summary

# ==========================================
# [Main UI]
# ==========================================
st.title("ğŸ§  BrainBoard V49: Final Fix")
st.markdown("### ğŸ” V49 ì—…ë°ì´íŠ¸: ìˆ¨ì€ ì €í•­ ì°¾ê¸° (ê¸°ì¤€ ì™„í™”)")

@st.cache_resource
def load_models():
    return YOLO(MODEL_REAL_PATH), YOLO(MODEL_SYM_PATH)

try:
    model_real, model_sym = load_models()
    st.sidebar.success("âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
except Exception as e:
    st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    st.stop()

col1, col2 = st.columns(2)
ref_file = col1.file_uploader("1. íšŒë¡œë„(Schematic) ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])
tgt_file = col2.file_uploader("2. ì‹¤ë¬¼(Real Board) ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])

if ref_file and tgt_file:
    ref_image = Image.open(ref_file)
    tgt_image = Image.open(tgt_file)
    ref_cv = cv2.cvtColor(np.array(ref_image), cv2.COLOR_RGB2BGR)
    tgt_cv = cv2.cvtColor(np.array(tgt_image), cv2.COLOR_RGB2BGR)

    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (Analyze)"):
        with st.spinner("AIê°€ ë¶€í’ˆì„ ì •ë°€ íƒìƒ‰ ì¤‘..."):
            
            res_ref_img, ref_data = analyze_schematic(ref_cv.copy(), model_sym)
            res_tgt_img, tgt_data = analyze_real(tgt_cv.copy(), model_real)

            issues = []
            all_parts = set(ref_data['details'].keys()) | set(tgt_data['details'].keys())
            counts_match = True
            
            for part in all_parts:
                if part in ['wire', 'breadboard', 'text', 'hole']: continue
                
                ref_c = ref_data['details'].get(part, 0)
                tgt_c = tgt_data['details'].get(part, {}).get('count', 0)
                
                if ref_c != tgt_c:
                    issues.append(f"âš ï¸ {part.capitalize()} ê°œìˆ˜ ë¶ˆì¼ì¹˜ (íšŒë¡œë„:{ref_c}ê°œ vs ì‹¤ë¬¼:{tgt_c}ê°œ)")
                    counts_match = False
                else:
                    issues.append(f"âœ… {part.capitalize()} ê°œìˆ˜ ì¼ì¹˜ ({ref_c}ê°œ)")

            st.divider()
            
            if counts_match:
                st.success("ğŸ‰ íšŒë¡œ êµ¬ì„±ì´ ì™„ë²½í•©ë‹ˆë‹¤!")
            else:
                st.warning("âš ï¸ íšŒë¡œ êµ¬ì„±ì— ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.")
            
            for i in issues:
                if "âœ…" in i: st.caption(i)
                else: st.error(i)

            st.image(cv2.cvtColor(res_ref_img, cv2.COLOR_BGR2RGB), caption="PSpice íšŒë¡œë„ ë¶„ì„", use_column_width=True)
            st.image(cv2.cvtColor(res_tgt_img, cv2.COLOR_BGR2RGB), caption="ì‹¤ë¬¼ ë³´ë“œ ë¶„ì„ (ìˆ¨ì€ ì €í•­ íƒìƒ‰)", use_column_width=True)
