import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
from PIL import Image

# ==========================================
# [1. ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬]
# ==========================================
st.set_page_config(page_title="BrainBoard V14 (Strict Res / Status Board)", layout="wide")

MODEL_REAL_PATH = 'best.pt'
MODEL_SYM_PATH = 'symbol.pt'

# ì—°ê²° ê°ì§€ ë²”ìœ„
LEG_EXTENSION_RANGE = 180        

# ==========================================
# [2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜: í† ë„ˆë¨¼íŠ¸ ë¡œì§]
# ==========================================
def calculate_iou(box1, box2):
    x1, y1, x2, y2 = max(box1[0], box2[0]), max(box1[1], box2[1]), min(box1[2], box2[2]), min(box1[3], box2[3])
    inter = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - inter
    return inter / union if union > 0 else 0

def solve_overlap(parts, dist_thresh=0, iou_thresh=0.4):
    if not parts: return []
    parts.sort(key=lambda x: x.get('conf', 0), reverse=True)
    
    final = []
    for curr in parts:
        is_dup = False
        for k in final:
            iou = calculate_iou(curr['box'], k['box'])
            if iou > iou_thresh:
                is_dup = True; break
            
            x1 = max(curr['box'][0], k['box'][0])
            y1 = max(curr['box'][1], k['box'][1])
            x2 = min(curr['box'][2], k['box'][2])
            y2 = min(curr['box'][3], k['box'][3])
            inter_area = max(0, x2-x1) * max(0, y2-y1)
            curr_area = (curr['box'][2]-curr['box'][0]) * (curr['box'][3]-curr['box'][1])
            
            if curr_area > 0 and (inter_area / curr_area) > 0.7:
                is_dup = True; break

            if dist_thresh > 0:
                dist = math.sqrt((curr['center'][0]-k['center'][0])**2 + (curr['center'][1]-k['center'][1])**2)
                if dist < dist_thresh:
                    is_dup = True; break

        if not is_dup:
            final.append(curr)
    return final

def get_center(box):
    return ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)

# ==========================================
# [3. íšŒë¡œë„ ë¶„ì„]
# ==========================================
def analyze_schematic(img, model):
    res = model.predict(source=img, conf=0.01, verbose=False)
    
    raw = []
    for b in res[0].boxes:
        cls_id = int(b.cls[0])
        raw_name = model.names[cls_id].lower()
        conf = float(b.conf[0])
        
        raw.append({
            'name': raw_name, 
            'box': b.xyxy[0].tolist(), 
            'center': get_center(b.xyxy[0].tolist()),
            'conf': conf
        })
    
    clean = solve_overlap(raw, dist_thresh=0, iou_thresh=0.1)
    
    leftmost_idx = -1
    min_x = float('inf')
    if clean:
        for i, p in enumerate(clean):
            if p['center'][0] < min_x:
                min_x = p['center'][0]
                leftmost_idx = i

    summary_details = {}
    
    for i, p in enumerate(clean):
        raw_name = p['name']
        name = raw_name 
        
        if 'cap' in raw_name: name = 'capacitor'
        elif 'res' in raw_name: name = 'resistor'
        elif 'ind' in raw_name: name = 'inductor'
        elif 'dio' in raw_name: name = 'diode'
        elif any(x in raw_name for x in ['volt', 'batt', 'source']): name = 'source'

        if i == leftmost_idx:
            name = 'source'
        
        x1, y1, x2, y2 = map(int, p['box'])
        box_color = (255, 0, 0) if name == 'source' else (0, 0, 255)
        
        cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)
        cv2.putText(img, name, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, box_color, 2)
        
        summary_details[name] = summary_details.get(name, 0) + 1
        
    return img, {'total': len(clean), 'details': summary_details}

# ==========================================
# [4. ì‹¤ë¬¼ ë¶„ì„: ì €í•­ ê¸°ì¤€ 60%ë¡œ ìƒí–¥]
# ==========================================
def analyze_real(img, model):
    h, w, _ = img.shape
    
    res = model.predict(source=img, conf=0.10, verbose=False)
    
    bodies = []
    pins = [] 
    
    for b in res[0].boxes:
        name = model.names[int(b.cls[0])].lower()
        coords = b.xyxy[0].tolist()
        center = get_center(coords)
        conf = float(b.conf[0])
        
        # [í•µì‹¬ ìˆ˜ì •] ì €í•­ ê¸°ì¤€ 60%ë¡œ ê°•í™”
        if 'cap' in name: min_conf = 0.15      # ì»¤íŒ¨ì‹œí„°: 15% (ë†“ì¹˜ì§€ ì•Šê²Œ)
        elif 'res' in name: min_conf = 0.60    # [UP] ì €í•­: 60% (ê°€ì§œ ì»·)
        elif 'wire' in name: min_conf = 0.15   # ì™€ì´ì–´: 15%
        else: min_conf = 0.25
            
        if conf < min_conf: continue

        if any(x in name for x in ['pin', 'leg', 'lead']) and 'wire' not in name:
            pins.append({'center': center, 'box': coords})
        elif 'breadboard' in name:
            continue
        else:
            bodies.append({'name': name, 'box': coords, 'center': center, 'conf': conf, 'is_on': False})

    # ì¤‘ë³µ ì œê±°
    clean_bodies = solve_overlap(bodies, dist_thresh=50, iou_thresh=0.3)
    
    # [ì—°ê²° ë¡œì§]
    power_active = False
    for b in clean_bodies:
        if 'wire' in b['name'] and b['center'][1] < h * 0.45:
            power_active = True; break
    if not power_active:
        for p in pins:
            if p['center'][1] < h * 0.45:
                power_active = True; break

    if power_active:
        # (1) ì§ì ‘ ì—°ê²°
        for comp in clean_bodies:
            cy = comp['center'][1]
            if cy < h*0.48 or cy > h*0.52: 
                comp['is_on'] = True

        # (2) ê°„ì ‘ ì—°ê²°
        for _ in range(3): 
            for comp in clean_bodies:
                if comp['is_on']: continue 
                cx, cy = comp['center']
                
                # A. í•€(ë‹¤ë¦¬)
                for p in pins:
                    px, py = p['center']
                    if py < h*0.48 or py > h*0.52:
                         dist = math.sqrt((cx - px)**2 + (cy - py)**2)
                         if dist < LEG_EXTENSION_RANGE:
                             comp['is_on'] = True; break

                if comp['is_on']: continue

                # B. ë‹¤ë¥¸ ë¶€í’ˆ
                for other in clean_bodies:
                    if not other['is_on']: continue
                    ocx, ocy = other['center']
                    dist = math.sqrt((cx - ocx)**2 + (cy - ocy)**2)
                    if dist < LEG_EXTENSION_RANGE * 1.5:
                        comp['is_on'] = True; break

    off_count = 0
    real_details = {} 
    
    for comp in clean_bodies:
        is_on = comp['is_on']
        raw_name = comp['name']
        
        norm_name = raw_name
        label_name = "" 
        
        if 'res' in raw_name: 
            norm_name = 'resistor'; label_name = "RES"
        elif 'cap' in raw_name: 
            norm_name = 'capacitor'; label_name = "CAP"
        elif 'wire' in raw_name:
            label_name = "WIRE"
        else:
            label_name = raw_name[:3].upper()
        
        if 'wire' not in raw_name:
            real_details[norm_name] = real_details.get(norm_name, 0) + 1

        if is_on:
            color = (0, 255, 0)
            status = "ON"
        else:
            color = (0, 0, 255)
            status = "OFF"
            off_count += 1
        
        # ë°•ìŠ¤ í‘œì‹œ
        display_text = f"{label_name}: {status}"
        x1, y1, x2, y2 = map(int, comp['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)
        cv2.putText(img, display_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
    return img, {'off': off_count, 'total': len(clean_bodies), 'details': real_details}

# ==========================================
# [5. ë©”ì¸ UI]
# ==========================================
st.title("ğŸ§  BrainBoard V14 (Strict Res / Status Board)")
st.markdown("### 1. ë¶€í’ˆ ì¼ì¹˜ ì—¬ë¶€")
st.markdown("### 2. ì—°ê²° ìƒíƒœ")

@st.cache_resource
def load_models():
    return YOLO(MODEL_REAL_PATH), YOLO(MODEL_SYM_PATH)

try:
    model_real, model_sym = load_models()
    st.sidebar.success("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

col1, col2 = st.columns(2)
ref_file = col1.file_uploader("1. íšŒë¡œë„ ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])
tgt_file = col2.file_uploader("2. ì‹¤ë¬¼ ì‚¬ì§„ ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])

if ref_file and tgt_file:
    ref_image = Image.open(ref_file)
    tgt_image = Image.open(tgt_file)
    
    ref_cv = cv2.cvtColor(np.array(ref_image), cv2.COLOR_RGB2BGR)
    tgt_cv = cv2.cvtColor(np.array(tgt_image), cv2.COLOR_RGB2BGR)

    if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹¤í–‰"):
        with st.spinner("AI ë¶„ì„ ì¤‘..."):
            res_ref_img, ref_data = analyze_schematic(ref_cv.copy(), model_sym)
            res_tgt_img, tgt_data = analyze_real(tgt_cv.copy(), model_real)

            st.divider()
            
            # ------------------------------------------------
            # [ì‹ ê·œ ê¸°ëŠ¥] ë¶€í’ˆ í˜„í™©íŒ (Status Board)
            # ------------------------------------------------
            st.info("ğŸ“Š **ë¶€í’ˆ ì¸ì‹ í˜„í™©**")
            
            # ì €í•­ ê°œìˆ˜ ë¹„êµ
            r_ref = ref_data['details'].get('resistor', 0)
            r_tgt = tgt_data['details'].get('resistor', 0)
            st.write(f"- **ì €í•­ (Resistor):** íšŒë¡œë„ {r_ref}ê°œ vs ì‹¤ë¬¼ {r_tgt}ê°œ")
            
            # ì»¤íŒ¨ì‹œí„° ê°œìˆ˜ ë¹„êµ (ìš”ì²­í•˜ì‹  ë¶€ë¶„!)
            c_ref = ref_data['details'].get('capacitor', 0)
            c_tgt = tgt_data['details'].get('capacitor', 0)
            st.write(f"- **ì»¤íŒ¨ì‹œí„° (Capacitor):** íšŒë¡œë„ {c_ref}ê°œ vs ì‹¤ë¬¼ {c_tgt}ê°œ")

            st.divider()

            # ë¶ˆì¼ì¹˜ ê²€ì‚¬ (ì—ëŸ¬ ë©”ì‹œì§€ìš©)
            mismatch_errors = []
            if r_ref != r_tgt:
                mismatch_errors.append(f"âš ï¸ RESISTOR ë¶ˆì¼ì¹˜: íšŒë¡œë„ {r_ref}ê°œ vs ì‹¤ë¬¼ {r_tgt}ê°œ")
            if c_ref != c_tgt:
                mismatch_errors.append(f"âš ï¸ CAPACITOR ë¶ˆì¼ì¹˜: íšŒë¡œë„ {c_ref}ê°œ vs ì‹¤ë¬¼ {c_tgt}ê°œ")
            
            # ì´ë¯¸ì§€ ì¶œë ¥
            st.image(cv2.cvtColor(res_ref_img, cv2.COLOR_BGR2RGB), caption="íšŒë¡œë„ ë¶„ì„", use_column_width=True)
            st.image(cv2.cvtColor(res_tgt_img, cv2.COLOR_BGR2RGB), caption=f"ì‹¤ë¬¼ ë¶„ì„ (OFF: {tgt_data['off']})", use_column_width=True)
            
            if mismatch_errors:
                st.error("âŒ íšŒë¡œ êµ¬ì„±ì´ ë‹¤ë¦…ë‹ˆë‹¤ (ë¶€í’ˆ ê°œìˆ˜ ë¶ˆì¼ì¹˜)")
                for err in mismatch_errors:
                    st.write(err)
            elif tgt_data['off'] > 0:
                st.error(f"âŒ ë¶€í’ˆ ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤ ({tgt_data['off']}ê°œ OFF)")
            else:
                st.success("âœ… ì™„ë²½í•©ë‹ˆë‹¤! (ë¶€í’ˆ ì¼ì¹˜ & ì „ì› ì—°ê²° ì„±ê³µ)")
