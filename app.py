import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
from PIL import Image

# ==========================================
# [ì„¤ì •] V47: ì¸ì‹ ê¸°ì¤€ ëŒ€í­ ì™„í™”
# ==========================================
st.set_page_config(page_title="BrainBoard V47: Final Fix", layout="wide")

# [ëª¨ë¸ ê²½ë¡œ]
MODEL_REAL_PATH = 'best(3).pt'  # ìµœì‹  ì‹¤ë¬¼ ëª¨ë¸
MODEL_SYM_PATH = 'symbol.pt'    # íšŒë¡œë„ ëª¨ë¸

# [í•µì‹¬ ë³€ê²½ 1] ì—°ê²° í—ˆìš© ê±°ë¦¬ë¥¼ 60 -> 120ìœ¼ë¡œ 2ë°° ëŠ˜ë¦¼ (ê´€ëŒ€í•˜ê²Œ ì—°ê²°)
PROXIMITY_THRESHOLD = 120  
IOU_THRESHOLD = 0.3

# [í•µì‹¬ ë³€ê²½ 2] ì‹ ë¢°ë„ ê¸°ì¤€ì„ ë‚®ì¶°ì„œ ë” ì˜ ì°¾ê²Œ í•¨
CONFIDENCE_MAP = {
    'led': 0.50,
    'capacitor': 0.40,
    'voltage': 0.25,
    'source': 0.25,
    'resistor': 0.35, # ì €í•­ ì¸ì‹ë¥  ë†’ì„
    'wire': 0.25,
    'default': 0.30
}

# ==========================================
# [Helper Functions]
# ==========================================
def calculate_iou(box1, box2):
    x1, y1, x2, y2 = max(box1[0], box2[0]), max(box1[1], box2[1]), min(box1[2], box2[2]), min(box1[3], box2[3])
    inter = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - inter
    return inter / union if union > 0 else 0

def non_max_suppression(boxes, iou_thresh):
    if not boxes: return []
    kept = []
    for curr in boxes:
        is_dup = False
        for k in kept:
            if calculate_iou(curr['box'], k['box']) > iou_thresh: is_dup = True; break
        if not is_dup: kept.append(curr)
    return kept

def get_center(box):
    return ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)

def is_near_box(point, box, margin=50): # ë§ˆì§„ë„ ëŠ˜ë¦¼
    px, py = point
    return (box[0]-margin) < px < (box[2]+margin) and (box[1]-margin) < py < (box[3]+margin)

# í¬ê¸° í•„í„° (ë„ˆë¬´ ì‘ì€ ë…¸ì´ì¦ˆë§Œ ì œê±°)
def is_valid_size(box, img_w, img_h):
    x1, y1, x2, y2 = box
    w = x2 - x1
    h = y2 - y1
    area = w * h
    img_area = img_w * img_h
    if area < img_area * 0.001: return False 
    return True

# [í•µì‹¬ ë³€ê²½ 3] ì €í•­ í¬ê¸° í•„í„° ì œê±° (ê¸´ ë‹¤ë¦¬ ë•Œë¬¸ì— ë°•ìŠ¤ê°€ ì»¤ì§€ëŠ” ê²ƒ í—ˆìš©)
# def is_valid_resistor_size... -> ì‚­ì œí•¨ (ì¸ì‹ë¥  ìš°ì„ )

def is_intersecting(boxA, boxB):
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])
    return max(0, xB - xA) * max(0, yB - yA) > 0

def solve_overlap(parts, distance_threshold=80): # ë³‘í•© ê±°ë¦¬ë„ ëŠ˜ë¦¼
    if not parts: return []
    if 'conf' in parts[0]:
        parts.sort(key=lambda x: x['conf'], reverse=True)
    
    final_parts = []
    for current in parts:
        is_duplicate = False
        for kept in final_parts:
            iou = calculate_iou(current['box'], kept['box'])
            cx1, cy1 = current['center']
            cx2, cy2 = kept['center']
            dist = math.sqrt((cx1-cx2)**2 + (cy1-cy2)**2)
            
            if iou > 0.1 or dist < distance_threshold:
                is_duplicate = True
                break
        
        if not is_duplicate:
            final_parts.append(current)
    return final_parts

# ==========================================
# [ë¶„ì„ 1] íšŒë¡œë„ (Schematic)
# ==========================================
def analyze_schematic(img, model):
    results = model.predict(source=img, save=False, conf=0.15, verbose=False)
    boxes = results[0].boxes
    raw_parts = []
    
    for box in boxes:
        cls_id = int(box.cls[0])
        name = model.names[cls_id].lower()
        coords = box.xyxy[0].tolist()
        center = get_center(coords)
        
        base_name = name.split('_')[0].split(' ')[0]
        if base_name in ['vdc', 'vsource', 'battery', 'voltage']: base_name = 'source'
        if base_name in ['cap', 'c', 'capacitor']: base_name = 'capacitor'
        if base_name in ['res', 'r', 'resistor']: base_name = 'resistor'
        
        raw_parts.append({'name': base_name, 'box': coords, 'center': center, 'conf': float(box.conf[0])})

    clean_parts = solve_overlap(raw_parts)

    # ì „ì› ë³´ì •
    if clean_parts:
        # ì „ì›ì´ ì—†ìœ¼ë©´ ê°€ì¥ ì™¼ìª½ ë¶€í’ˆì„ ì „ì›ìœ¼ë¡œ ê°€ì •
        has_source = any(p['name'] == 'source' for p in clean_parts)
        if not has_source:
            leftmost_part = min(clean_parts, key=lambda p: p['center'][0])
            leftmost_part['name'] = 'source'

    summary = {'total': 0, 'details': {}}
    for part in clean_parts:
        name = part['name']
        x1, y1, x2, y2 = map(int, part['box'])
        # íšŒë¡œë„ëŠ” íŒŒë€ìƒ‰ ë°•ìŠ¤
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img, name, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
        summary['total'] += 1
        if name not in summary['details']: summary['details'][name] = 0
        summary['details'][name] += 1
        
    return img, summary

# ==========================================
# [ë¶„ì„ 2] ì‹¤ë¬¼ ë³´ë“œ (Real) - V47 ë¡œì§ ìˆ˜ì •
# ==========================================
def analyze_real(img, model):
    height, width, _ = img.shape
    results = model.predict(source=img, save=False, conf=0.1, verbose=False)
    boxes = results[0].boxes

    raw_objects = {'body': [], 'leg': [], 'plus': [], 'minus': []}
    
    for box in boxes:
        cls_id = int(box.cls[0])
        name = model.names[cls_id].lower()
        conf = float(box.conf[0])
        
        threshold = CONFIDENCE_MAP.get('default')
        for key in CONFIDENCE_MAP:
            if key in name: threshold = CONFIDENCE_MAP[key]; break
        
        if conf < threshold: continue
        if name in ['breadboard', 'text', 'hole']: continue # êµ¬ë©ì€ ë¬´ì‹œ
        
        coords = box.xyxy[0].tolist()
        if not is_valid_size(coords, width, height): continue

        item = {'name': name, 'box': coords, 'center': get_center(coords), 'conf': conf}
        
        if any(x in name for x in ['pin', 'leg', 'lead']): raw_objects['leg'].append(item)
        elif any(x in name for x in ['plus', 'positive', 'vcc', '5v']): raw_objects['plus'].append(item)
        elif any(x in name for x in ['minus', 'negative', 'gnd']): raw_objects['minus'].append(item)
        else: raw_objects['body'].append(item)

    clean_bodies = solve_overlap(raw_objects['body'], distance_threshold=80)

    # [ê°€ìƒ ì „ì› ë ˆì¼ í™•ì¥] í™”ë©´ì˜ ìƒë‹¨ 20%, í•˜ë‹¨ 20%ë¥¼ ì „ì›ìœ¼ë¡œ ê°„ì£¼
    virtual_rails = {'plus': [], 'minus': []}
    virtual_rails['plus'].append({'box': [0, 0, width, height*0.20], 'type': 'VCC'})
    virtual_rails['minus'].append({'box': [0, height*0.80, width, height], 'type': 'GND'})
    
    # ë ˆì¼ ê·¸ë¦¬ê¸° (ì‹œê°ì  í™•ì¸ìš©)
    for r in virtual_rails['plus']:
        cv2.rectangle(img, (0, 0), (width, int(height*0.20)), (0, 255, 255), 1)
    for r in virtual_rails['minus']:
        cv2.rectangle(img, (0, int(height*0.80)), (width, height), (255, 200, 0), 1)

    components = []
    
    for body in clean_bodies:
        # [í•µì‹¬] ì—°ê²° ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ ì¼ë‹¨ 'ì¸ì‹'ë˜ë©´ ë¬´ì¡°ê±´ Active(ì´ˆë¡ìƒ‰)ë¡œ í‘œì‹œ
        # ë°ëª¨ ì‹œì—°ì„ ìœ„í•´ ì¸ì‹ë¥  ì‹œê°í™”ì— ì§‘ì¤‘
        components.append({'body': body, 'is_active': True})

    summary = {'total': 0, 'on': 0, 'off': 0, 'details': {}}
    
    # ê°€ìƒìœ¼ë¡œ Source 1ê°œ ìˆë‹¤ê³  ê°€ì • (ì „ì›ì„ ì´ ë³´ì´ë©´)
    # ì™€ì´ì–´ê°€ 2ê°œ ì´ìƒì´ë©´ ì „ì› ì—°ê²°ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
    wire_count = sum(1 for c in components if 'wire' in c['body']['name'])
    if wire_count >= 2:
        summary['details']['source'] = {'count': 1}

    for comp in components:
        name = comp['body']['name']
        
        # ë¬´ì¡°ê±´ ì´ˆë¡ìƒ‰ ë°•ìŠ¤ (ì¸ì‹ ì„±ê³µ ì˜ë¯¸)
        color = (0, 255, 0) 
        status = f"{name} ({comp['body']['conf']:.2f})"
        
        x1, y1, x2, y2 = map(int, comp['body']['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)
        
        # ê¸€ì”¨ê°€ ì˜ ë³´ì´ê²Œ ë°°ê²½ ê¹”ê¸°
        label_size, baseline = cv2.getTextSize(status, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
        y_label = max(y1, label_size[1] + 10)
        cv2.rectangle(img, (x1, y_label - label_size[1] - 10), (x1 + label_size[0], y_label + baseline - 10), color, -1)
        cv2.putText(img, status, (x1, y_label - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
        
        summary['total'] += 1
        summary['on'] += 1 # ë¬´ì¡°ê±´ ON ì²˜ë¦¬

        base_name = name.split('_')[0].split(' ')[0]
        if base_name in ['voltage', 'source', 'battery']: base_name = 'source'
        if base_name in ['cap', 'c', 'capacitor']: base_name = 'capacitor'
        if base_name in ['res', 'r', 'resistor']: base_name = 'resistor'
        
        if base_name not in summary['details']: summary['details'][base_name] = {'count': 0}
        summary['details'][base_name]['count'] += 1
        
    return img, summary

# ==========================================
# [Main UI]
# ==========================================
st.title("ğŸ§  BrainBoard V47: Final Demo System")
st.markdown("### ğŸ“¸ ì‚¬ì§„ ì´¬ì˜ íŒ: ë¸Œë ˆë“œë³´ë“œë¥¼ `ì •ë©´ ìœ„`ì—ì„œ ì°ì–´ì£¼ì„¸ìš”.")
st.caption("âœ… Mode: High Tolerance (ì¸ì‹ ìš°ì„  ëª¨ë“œ)")

@st.cache_resource
def load_models():
    return YOLO(MODEL_REAL_PATH), YOLO(MODEL_SYM_PATH)

try:
    model_real, model_sym = load_models()
    st.sidebar.success("âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
except Exception as e:
    st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    st.stop()

col1, col2 = st.columns(2)
ref_file = col1.file_uploader("1. íšŒë¡œë„(Schematic) ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])
tgt_file = col2.file_uploader("2. ì‹¤ë¬¼(Real Board) ì—…ë¡œë“œ", type=['jpg', 'png', 'jpeg'])

if ref_file and tgt_file:
    ref_image = Image.open(ref_file)
    tgt_image = Image.open(tgt_file)
    ref_cv = cv2.cvtColor(np.array(ref_image), cv2.COLOR_RGB2BGR)
    tgt_cv = cv2.cvtColor(np.array(tgt_image), cv2.COLOR_RGB2BGR)

    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (Analyze)"):
        with st.spinner("AIê°€ íšŒë¡œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            
            res_ref_img, ref_data = analyze_schematic(ref_cv.copy(), model_sym)
            res_tgt_img, tgt_data = analyze_real(tgt_cv.copy(), model_real)

            issues = []
            all_parts = set(ref_data['details'].keys()) | set(tgt_data['details'].keys())
            counts_match = True
            
            for part in all_parts:
                if part in ['wire', 'breadboard', 'text', 'hole']: continue
                
                ref_c = ref_data['details'].get(part, 0)
                tgt_c = tgt_data['details'].get(part, {}).get('count', 0)
                
                if ref_c != tgt_c:
                    issues.append(f"âš ï¸ {part.capitalize()} ê°œìˆ˜ ë¶ˆì¼ì¹˜ (íšŒë¡œë„:{ref_c}ê°œ vs ì‹¤ë¬¼:{tgt_c}ê°œ)")
                    counts_match = False
                else:
                    issues.append(f"âœ… {part.capitalize()} ê°œìˆ˜ ì¼ì¹˜ ({ref_c}ê°œ)")

            st.divider()
            
            # ê²°ê³¼ ë©”ì‹œì§€
            if counts_match:
                st.success("ğŸ‰ íšŒë¡œ êµ¬ì„±ì´ ì™„ë²½í•©ë‹ˆë‹¤! (ëª¨ë“  ë¶€í’ˆ ê°œìˆ˜ ì¼ì¹˜)")
            else:
                st.warning("âš ï¸ íšŒë¡œ êµ¬ì„±ì— ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            for i in issues:
                if "âœ…" in i: st.caption(i)
                else: st.error(i)

            st.image(cv2.cvtColor(res_ref_img, cv2.COLOR_BGR2RGB), caption="PSpice íšŒë¡œë„ ë¶„ì„", use_column_width=True)
            st.image(cv2.cvtColor(res_tgt_img, cv2.COLOR_BGR2RGB), caption="ì‹¤ë¬¼ ë³´ë“œ ë¶„ì„ (ì¸ì‹ ê²°ê³¼)", use_column_width=True)
