import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
from PIL import Image
from collections import defaultdict
import gc
from datetime import datetime

# ==========================================
# [ì„¤ì •] CircuitMate AI (V70: Design & History)
# ==========================================
st.set_page_config(page_title="CircuitMate AI", layout="wide", page_icon="âš¡")

# [ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”] íˆìŠ¤í† ë¦¬ ì €ì¥ì„ ìœ„í•œ ë©”ëª¨ë¦¬ ê³µê°„
if 'history' not in st.session_state:
    st.session_state['history'] = []

REAL_MODEL_PATH = 'best(3).pt' 
MODEL_SYM_PATH = 'symbol.pt'

# ==========================================
# [Core Logic] V69ì˜ ì™„ë²½í•œ ì•Œê³ ë¦¬ì¦˜ (ë³€ê²½ ì—†ìŒ)
# ==========================================
def resize_image_smart(image, max_size=1024):
    h, w = image.shape[:2]
    if max(h, w) > max_size:
        scale = max_size / max(h, w)
        new_w, new_h = int(w * scale), int(h * scale)
        return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return image

def get_center(box):
    return ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)

def calculate_iou(box1, box2):
    x1 = max(box1[0], box2[0]); y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2]); y2 = min(box1[3], box2[3])
    inter = max(0, x2 - x1) * max(0, y2 - y1)
    union = ((box1[2]-box1[0])*(box1[3]-box1[1])) + ((box2[2]-box2[0])*(box2[3]-box2[1])) - inter
    return inter / union if union > 0 else 0

def normalize_name(name):
    name = name.lower()
    if 'res' in name: return 'resistor'
    if 'cap' in name: return 'capacitor'
    if 'wire' in name: return 'wire'
    if any(x in name for x in ['source', 'batt', 'volt', 'vdc']): return 'source'
    if any(x in name for x in ['leg', 'pin', 'lead']): return 'leg'
    return name

def solve_overlap_real(parts):
    if not parts: return []
    parts.sort(key=lambda x: x.get('conf', 0), reverse=True)
    final = []
    for curr in parts:
        is_dup = False
        for k in final:
            iou = calculate_iou(curr['box'], k['box'])
            dist = math.sqrt((curr['center'][0]-k['center'][0])**2 + (curr['center'][1]-k['center'][1])**2)
            if curr['name'] != 'leg' and (iou > 0.4 or dist < 60): 
                is_dup = True; break
        if not is_dup: final.append(curr)
    return final

def sort_parts_LRTB(parts, image_width):
    if not parts: return []
    parts.sort(key=lambda x: x['center'][0])
    sorted_sequence = []
    current_column = []
    X_THRESHOLD = image_width * 0.10
    
    current_column.append(parts[0])
    ref_x = parts[0]['center'][0]
    
    for i in range(1, len(parts)):
        curr = parts[i]
        curr_x = curr['center'][0]
        if abs(curr_x - ref_x) < X_THRESHOLD:
            current_column.append(curr)
        else:
            current_column.sort(key=lambda x: x['center'][1])
            sorted_sequence.extend(current_column)
            current_column = [curr]
            ref_x = curr_x
            
    if current_column:
        current_column.sort(key=lambda x: x['center'][1])
        sorted_sequence.extend(current_column)
    return sorted_sequence

def analyze_schematic(img, model):
    img = resize_image_smart(img)
    w = img.shape[1]
    results = model.predict(source=img, save=False, conf=0.05, verbose=False)
    raw_parts = []
    for box in results[0].boxes:
        raw_name = model.names[int(box.cls[0])]
        norm_name = normalize_name(raw_name)
        if norm_name == 'wire' or norm_name == 'leg': continue
        coords = box.xyxy[0].tolist()
        raw_parts.append({'name': norm_name, 'box': coords, 'center': get_center(coords), 'conf': float(box.conf[0])})

    parts = []
    raw_parts.sort(key=lambda x: x['conf'], reverse=True)
    for p in raw_parts:
        if not any(calculate_iou(p['box'], k['box']) > 0.1 for k in parts): parts.append(p)

    if parts and not any(p['name'] == 'source' for p in parts):
         leftmost = min(parts, key=lambda p: p['center'][0])
         leftmost['name'] = 'source'

    for p in parts:
        x1, y1, x2, y2 = map(int, p['box'])
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img, p['name'], (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

    sorted_parts = sort_parts_LRTB(parts, w)
    for i, p in enumerate(sorted_parts):
        cx, cy = map(int, p['center'])
        cv2.circle(img, (cx, cy), 15, (0, 0, 255), -1)
        cv2.putText(img, str(i+1), (cx-5, cy+5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    return img, {'parts': sorted_parts}

def analyze_real(img, model):
    img = resize_image_smart(img)
    h, w, _ = img.shape
    res = model.predict(source=img, conf=0.10, verbose=False)
    raw_objects = []
    for b in res[0].boxes:
        raw_name = model.names[int(b.cls[0])]
        norm_name = normalize_name(raw_name)
        conf = float(b.conf[0])
        if norm_name == 'capacitor' and conf < 0.20: continue
        if norm_name == 'resistor' and conf < 0.25: continue
        if 'breadboard' in raw_name: continue
        coords = b.xyxy[0].tolist()
        raw_objects.append({'name': norm_name, 'box': coords, 'center': get_center(coords), 'conf': conf})

    parts_candidates = [p for p in raw_objects if p['name'] != 'leg']
    legs = [p for p in raw_objects if p['name'] == 'leg']
    parts = solve_overlap_real(parts_candidates)

    TOP_RAIL = h * 0.20; BOTTOM_RAIL = h * 0.80
    has_source = False
    if any(p['name'] == 'source' for p in parts): has_source = True
    if not has_source:
        for p in raw_objects:
            if p['center'][1] < TOP_RAIL or p['center'][1] > BOTTOM_RAIL:
                if p['name'] == 'wire' or p['name'] == 'leg':
                    has_source = True; break
    if has_source and not any(p['name'] == 'source' for p in parts):
        parts.append({'name': 'source', 'box': [0,0,0,0], 'center': (0,0), 'conf': 1.0})

    for p in parts:
        if p['name'] == 'wire': continue
        color = (0, 255, 0)
        if p['name'] == 'source': color = (0, 255, 255)
        if p['box'][2] > 0:
            x1, y1, x2, y2 = map(int, p['box'])
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)
            cv2.putText(img, p['name'].upper(), (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        elif p['name'] == 'source':
            cv2.putText(img, "SOURCE DETECTED", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

    main_parts = [p for p in parts if p['name'] != 'wire']
    sorted_parts = sort_parts_LRTB(main_parts, w)

    for i, p in enumerate(sorted_parts):
        if p['box'][2] > 0:
            cx, cy = map(int, p['center'])
            cv2.circle(img, (cx, cy), 15, (0, 0, 255), -1)
            cv2.putText(img, str(i+1), (cx-5, cy+5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    return img, {'parts': sorted_parts}

# ==========================================
# [UI/UX] Sidebar & Main Layout
# ==========================================

# [ì‚¬ì´ë“œë°”] ëª¨ë¸ ë¡œë“œ ë° íˆìŠ¤í† ë¦¬ ê¸°ëŠ¥
with st.sidebar:
    st.title("âš¡ CircuitMate AI")
    st.caption("Your Personal Circuit Assistant")
    st.divider()
    
    # ëª¨ë¸ ë¡œë“œ ìƒíƒœ
    try:
        if 'models_loaded' not in st.session_state:
            gc.collect()
            st.session_state['model_real'] = YOLO(REAL_MODEL_PATH)
            st.session_state['model_sym'] = YOLO(MODEL_SYM_PATH)
            st.session_state['models_loaded'] = True
        st.success("âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        st.stop()

    st.divider()
    
    # [íˆìŠ¤í† ë¦¬ ê¸°ëŠ¥] ChatGPT ìŠ¤íƒ€ì¼ ê¸°ë¡
    st.markdown("### ğŸ•’ ìµœê·¼ ê²€ì¦ ê¸°ë¡")
    if len(st.session_state['history']) == 0:
        st.caption("ì•„ì§ ê²€ì¦ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ìµœì‹ ìˆœìœ¼ë¡œ ë³´ì—¬ì£¼ê¸°
        for idx, item in enumerate(reversed(st.session_state['history'])):
            with st.expander(f"{item['time']} - {item['status']}"):
                st.write(item['detail'])

# [ë©”ì¸ í™”ë©´] ëŒ€í™”í˜• UI êµ¬ì„±
st.markdown("""
# ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”! íšŒë¡œ ê²€ì¦ì„ ë„ì™€ë“œë¦´ê²Œìš”.
íšŒë¡œë„ì™€ ì‹¤ë¬¼ ë¸Œë ˆë“œë³´ë“œ ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì‹œë©´, **ë¶€í’ˆì˜ ì¢…ë¥˜ì™€ ì—°ê²° ìˆœì„œ**ë¥¼ ê¼¼ê¼¼í•˜ê²Œ ë¹„êµí•´ë“œë¦½ë‹ˆë‹¤.
""")

col1, col2 = st.columns(2)
with col1:
    st.markdown("### 1ï¸âƒ£ íšŒë¡œë„ (Schematic)")
    ref_file = st.file_uploader("íšŒë¡œë„ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì£¼ì„¸ìš”", type=['jpg', 'png', 'jpeg'])

with col2:
    st.markdown("### 2ï¸âƒ£ ì‹¤ë¬¼ ì‚¬ì§„ (Real Board)")
    tgt_file = st.file_uploader("ë¸Œë ˆë“œë³´ë“œ ì‚¬ì§„ì„ ë„£ì–´ì£¼ì„¸ìš”", type=['jpg', 'png', 'jpeg'])

# ë¶„ì„ ë¡œì§
if ref_file and tgt_file:
    ref_image = Image.open(ref_file)
    tgt_image = Image.open(tgt_file)
    ref_cv = cv2.cvtColor(np.array(ref_image), cv2.COLOR_RGB2BGR)
    tgt_cv = cv2.cvtColor(np.array(tgt_image), cv2.COLOR_RGB2BGR)

    if st.button("âœ¨ ë¶„ì„ ì‹œì‘í•˜ê¸° (Analyze)", type="primary"):
        gc.collect()
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_text = "AIê°€ íšŒë¡œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!"
        my_bar = st.progress(0, text=progress_text)

        # ë¶„ì„ ì‹¤í–‰
        res_ref_img, ref_data = analyze_schematic(ref_cv.copy(), st.session_state['model_sym'])
        my_bar.progress(50, text="ì‹¤ë¬¼ ë³´ë“œì˜ ë¶€í’ˆì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        res_tgt_img, tgt_data = analyze_real(tgt_cv.copy(), st.session_state['model_real'])
        my_bar.progress(90, text="íšŒë¡œë„ì™€ ì‹¤ë¬¼ì„ ë¹„êµ ê²€ì¦ ì¤‘ì…ë‹ˆë‹¤...")

        # --------------------------------------------------------
        # ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        # --------------------------------------------------------
        st.divider()
        st.markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸")

        # 1. BOM ë¹„êµ
        ref_counts = defaultdict(int)
        tgt_counts = defaultdict(int)
        for p in ref_data['parts']: ref_counts[p['name']] += 1
        for p in tgt_data['parts']: tgt_counts[p['name']] += 1
        
        all_keys = set(ref_counts.keys()) | set(tgt_counts.keys())
        bom_match = True
        bom_data = []
        
        for k in all_keys:
            if k == 'wire': continue
            r = ref_counts[k]; t = tgt_counts[k]
            status = "âœ… ì¼ì¹˜" if r == t else "âš ï¸ í™•ì¸ í•„ìš”"
            bom_data.append({"ë¶€í’ˆëª…": k.upper(), "íšŒë¡œë„ ê°œìˆ˜": r, "ì‹¤ë¬¼ ê°œìˆ˜": t, "ìƒíƒœ": status})
            if r != t: bom_match = False
        
        col_res1, col_res2 = st.columns([1, 1])
        
        with col_res1:
            st.markdown("### ğŸ“‹ ë¶€í’ˆ ëª©ë¡ í™•ì¸")
            st.dataframe(bom_data, hide_index=True)

        # 2. ìˆœì„œ ë¹„êµ
        ref_list = [p['name'] for p in ref_data['parts']]
        tgt_list = [p['name'] for p in tgt_data['parts']]
        
        is_seq_match = True
        
        with col_res2:
            st.markdown("### ğŸ”— ì—°ê²° ìˆœì„œ ê²€ì¦")
            if not bom_match:
                st.warning("âš ï¸ ë¶€í’ˆ ê°œìˆ˜ê°€ ë‹¬ë¼ì„œ ì •í™•í•œ ìˆœì„œ ë¹„êµê°€ ì–´ë µìŠµë‹ˆë‹¤.")
                st.caption(f"íšŒë¡œë„: {' â†’ '.join(ref_list)}")
                st.caption(f"ì‹¤ë¬¼: {' â†’ '.join(tgt_list)}")
            else:
                for i in range(len(ref_list)):
                    r_item = ref_list[i]
                    t_item = tgt_list[i]
                    if r_item == t_item:
                        st.info(f"**Step {i+1}:** {r_item.upper()} âœ… ì •ìƒ ì—°ê²°ë¨")
                    else:
                        st.error(f"**Step {i+1}:** ë¶ˆì¼ì¹˜ ê°ì§€! (íšŒë¡œë„: {r_item} vs ì‹¤ë¬¼: {t_item})")
                        is_seq_match = False
                
                if is_seq_match:
                    st.success("ì™„ë²½í•©ë‹ˆë‹¤! íšŒë¡œ ì—°ê²° ìˆœì„œê°€ ì •í™•í•´ìš”. ğŸ‰")
                    st.balloons()

        my_bar.empty() # ì§„í–‰ë°” ì œê±°

        # 3. ì‹œê°í™” ì´ë¯¸ì§€
        st.markdown("### ğŸ“· AI ì¸ì‹ í™”ë©´")
        img_col1, img_col2 = st.columns(2)
        with img_col1:
            st.image(cv2.cvtColor(res_ref_img, cv2.COLOR_BGR2RGB), caption="íšŒë¡œë„ ë¶„ì„ (ë²ˆí˜¸ëŠ” ì „ë¥˜ íë¦„ ìˆœì„œ)", use_column_width=True)
        with img_col2:
            st.image(cv2.cvtColor(res_tgt_img, cv2.COLOR_BGR2RGB), caption="ì‹¤ë¬¼ ë¶„ì„ (ë²ˆí˜¸ëŠ” ë°°ì¹˜ ìˆœì„œ)", use_column_width=True)

        # --------------------------------------------------------
        # [íˆìŠ¤í† ë¦¬ ì €ì¥]
        # --------------------------------------------------------
        timestamp = datetime.now().strftime("%H:%M:%S")
        status_msg = "ì„±ê³µ âœ…" if (bom_match and is_seq_match) else "ì‹¤íŒ¨ âŒ"
        
        # íˆìŠ¤í† ë¦¬ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
        detail_txt = f"ë¶€í’ˆ: {'ì¼ì¹˜' if bom_match else 'ë¶ˆì¼ì¹˜'} / ìˆœì„œ: {'ì¼ì¹˜' if is_seq_match else 'ë¶ˆì¼ì¹˜'}"
        
        # ì„¸ì…˜ì— ì¶”ê°€
        st.session_state['history'].append({
            "time": timestamp,
            "status": status_msg,
            "detail": detail_txt
        })
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del res_ref_img, res_tgt_img
        gc.collect()
